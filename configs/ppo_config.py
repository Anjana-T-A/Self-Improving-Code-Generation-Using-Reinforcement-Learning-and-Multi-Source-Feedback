# from trl import PPOConfig

# ppo_config = PPOConfig(
#     model_name="bigcode/starcoderbase",  # change per model
#     learning_rate=1e-5,
#     log_with=None,  # Set to "wandb" if using it
#     batch_size=1,
#     mini_batch_size=1,
#     optimize_cuda_cache=True
# )
