{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6419b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tf_anjana (Python 3.9.23)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n tf_anjana ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate pylint accelerate peft -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e054bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tf_anjana (Python 3.9.23)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n tf_anjana ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mbpp = load_dataset(\"mbpp\", split=\"train[:100]\")  # Use a small subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203291fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "def run_unit_test(code, test_code):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as f:\n",
    "        f.write((code + \"\\\\n\" + test_code).encode())\n",
    "        f.flush()\n",
    "        result = subprocess.run([\"python3\", f.name], capture_output=True, text=True)\n",
    "    return result.returncode == 0, result.stderr\n",
    "\n",
    "def run_pylint(code):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as f:\n",
    "        f.write(code.encode())\n",
    "        f.flush()\n",
    "        result = subprocess.run([\"pylint\", f.name, \"--score\", \"y\", \"-rn\", \"-sn\"], capture_output=True, text=True)\n",
    "    return result.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a69fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_training_example(prompt, generated_code, test_result, pylint_feedback, reference_solution):\n",
    "    return {\n",
    "        \"input\": f\"# Problem:\\\\n{prompt}\\\\n# Generated Code:\\\\n{generated_code}\\\\n# Unit Test Feedback:\\\\n{test_result}\\\\n# Pylint Feedback:\\\\n{pylint_feedback}\",\n",
    "        \"output\": reference_solution\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_anjana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
